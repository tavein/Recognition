问题二
=========




目标
------

需要识别图中物体的运行轨迹

  .. figure:: ./_static/BMPRing/Ring01.bmp

  .. figure:: ./_static/BMPRing/Ring02.bmp


问题的分析
-------

.. code:: PlainText

  完全照搬问题一的办法，优化网络结构设计（VGG系列网络），最好的效果只是19张图片识别出其中6张。
  随着问题变复杂，加之需要使用尽量少的图片来做训练，卷积网络的效果变得不太理想。
  但是本质上没有发生什么大的变化，无非是查阅一下资料，研究一下前人的工作，利用成果。
  在这个题里，具体体现就是根据cv领域研究者验证有效的方法进行数据预处理和特征提取。

流程
--------


流程
-------

和问题一本质上是一致的。

同问题1流程一致。

变化的地方在于，

- 滑窗法提取了窗口数据后，需要将其转化为传统ML模型接受的数据格式，也就是fixed-N维向量。
  这一步我使用的是Hog特征，具体的参数配置见代码文件`Q2Support.py <https://github.com/thautwarm/Recognition/tree/master/PedestrianRecognition/_static/Pedestrian/Question2/Q2Support.py>`_。

- 得到Hog特征后，降个维。对于训练数据，我们拿她做一个预训练，用随机森林训练后，
  给出特征的不同维度在分类时所起的影响权重。我发现在原始的6k+维度中有99%以上的特征并没有用到，将他们削去，
  最后降到32维（欸，记得好像是32维，10多天了有点忘...）。
  然后对降维后的数据做训练，并保留降维规则，任何时候提取Hog特征后都需要使用这个降维规则降维。

- 另外提一句，因为之前自己写camshift，meanshift算法，觉得颜色直方分布特征也应该对分类有用，
  但是降维那步告诉了我，凭感觉提取特征还是会有错误的...

预测结果
------

`pillow画图 <http://thautsite.duapp.com/gsrcMMq2>`_
`opencv画图 <http://thautsite.duapp.com/gsrcMMq2CV>`_

一直到第二题结束，都完全是一板一眼的机器学习。结果都非常完美。

真正觉得自己做了点东西的地方在第三题，我想为我的**SIFT特征匹配位置特异性得分矩阵**申请专利喵
